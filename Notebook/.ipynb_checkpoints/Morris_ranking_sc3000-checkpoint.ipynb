{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(r'C:\\Users\\moallemie\\EMAworkbench-master')\n",
    "sys.path.append(r'C:\\Users\\moallemie\\EM_analysis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from ema_workbench import load_results, ema_logging\n",
    "from ema_workbench.em_framework.salib_samplers import get_SALib_problem\n",
    "from SALib.analyze import morris"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the model, uncertainities, and outcomes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[MainProcess/INFO] using 64 bit vensim\n",
      "[MainProcess/INFO] pool started\n",
      "[MainProcess/INFO] performing 318000 scenarios * 1 policies * 1 model(s) = 318000 experiments\n",
      "[MainProcess/INFO] 31800 cases completed\n",
      "[MainProcess/INFO] 63600 cases completed\n",
      "[MainProcess/INFO] 95400 cases completed\n",
      "[MainProcess/INFO] 127200 cases completed\n",
      "[MainProcess/INFO] 159000 cases completed\n",
      "[MainProcess/INFO] 190800 cases completed\n",
      "[MainProcess/INFO] 222600 cases completed\n",
      "[MainProcess/INFO] 254400 cases completed\n",
      "[MainProcess/INFO] 286200 cases completed\n",
      "[MainProcess/INFO] 318000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] terminating pool\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "took 5970.964630365372 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[MainProcess/INFO] results saved successfully to D:\\moallemie\\EM_analysis\\Data\\SDG_experiments_sc2000.tar.gz\n"
     ]
    }
   ],
   "source": [
    "# Here we only generate experiments for loading the necessary components. \n",
    "#The actual results will be loaded in the next cell.\n",
    "\n",
    "# Open Excel input data from the notebook directory before runnign the code in multi-processing.\n",
    "# Close the folder where the results will be saved in multi-processing.\n",
    "# This line must be at the beginning for multi processing. \n",
    "if __name__ == '__main__':\n",
    "    \n",
    "   \n",
    "    ema_logging.log_to_stderr(ema_logging.INFO)\n",
    "    \n",
    "    #The model must be imoorted as .py file in parallel processing.\n",
    "    from Model_init import vensimModel\n",
    "    \n",
    "    from ema_workbench import (TimeSeriesOutcome, \n",
    "                                   perform_experiments,\n",
    "                                   RealParameter, \n",
    "                                   CategoricalParameter,\n",
    "                                   ema_logging, \n",
    "                                   save_results,\n",
    "                                  load_results)\n",
    "\n",
    "    directory = 'C:/Users/moallemie/EM_analysis/Model/'\n",
    "\n",
    "    df_unc = pd.read_excel(directory+'ScenarioFramework.xlsx', sheet_name='Uncertainties')\n",
    "    \n",
    "    # 0.5/1.5 multiplication is added to previous Min/Max cells for parameters with Reference values 0 \n",
    "    #or min/max manually set in the spreadsheet   \n",
    "    df_unc['Min'] = df_unc['Min'] + df_unc['Reference'] * 0.75\n",
    "    df_unc['Max'] = df_unc['Max'] + df_unc['Reference'] * 1.25\n",
    "\n",
    "    vensimModel.uncertainties = [RealParameter(row['Uncertainty'], row['Min'], row['Max']) for index, row in df_unc.iterrows()]\n",
    "\n",
    "    df_out = pd.read_excel(directory+'ScenarioFramework.xlsx', sheet_name='Outcomes')\n",
    "    vensimModel.outcomes = [TimeSeriesOutcome(out) for out in df_out['Outcome']]\n",
    "\n",
    "\n",
    "  \n",
    "\n",
    "    from ema_workbench import MultiprocessingEvaluator\n",
    "    from ema_workbench.em_framework.evaluators import (MC, LHS, FAST, FF, PFF, SOBOL, MORRIS)\n",
    "\n",
    "    import  time\n",
    "    start = time.time()\n",
    "\n",
    "    with MultiprocessingEvaluator(vensimModel, n_processes=220) as evaluator:\n",
    "        results = evaluator.perform_experiments(scenarios=3000, uncertainty_sampling=MORRIS)\n",
    "\n",
    "    \n",
    "    \n",
    "    end = time.time()\n",
    "    print(\"took {} seconds\".format(end-start))\n",
    "    \n",
    "    fn = 'D:/moallemie/EM_analysis/Data/SDG_experiments_sc3000.tar.gz'\n",
    "\n",
    "    save_results(results, fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiments, outcomes = results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating SA (Morris) metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sobol indice calculation as a function of number of scenarios and time\n",
    "\n",
    "def make_morris_df(scores, problem, outcome_var, sc, t):\n",
    "    scores_filtered = {k:scores[k] for k in ['mu_star','mu_star_conf','mu','sigma']}\n",
    "    Si_df = pd.DataFrame(scores_filtered, index=problem['names'])\n",
    "    sa_dir='C:/Users/moallemie/EM_analysis/Data/'\n",
    "    Si_df.to_csv(sa_dir+\"MorrisIndices_{}_sc{}_t{}.csv\".format(outcome_var, sc, t))\n",
    "    \n",
    "    Si_df.sort_values(by=['mu_star'], ascending=False, inplace=True)\n",
    "    Si_df = Si_df.head(20)\n",
    "    \n",
    "    Si_df = Si_df.iloc[::-1]\n",
    "\n",
    "    indices = Si_df[['mu_star','mu']]\n",
    "    errors = Si_df[['mu_star_conf','sigma']]\n",
    "    return indices, errors\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the outcome variable, number of scenarios generated, and the timeslice you're interested in for SA\n",
    "sc = 3000\n",
    "t = 2100\n",
    "outcome_vars = list(outcomes.keys())[1:]\n",
    "\n",
    "inds ={}\n",
    "errs = {}\n",
    "problem = get_SALib_problem(vensimModel.uncertainties)\n",
    "for i, outcome_var in enumerate(outcome_vars):\n",
    "    X = experiments.iloc[:, :-3].values\n",
    "    Y = outcomes[outcome_var][:,-1]\n",
    "    scores = morris.analyze(problem, X, Y, print_to_console=False)\n",
    "    inds[outcome_var], errs[outcome_var] = make_morris_df(scores, problem, outcome_var, sc, t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting SA results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the ploting function\n",
    "def plot_scores(inds, errs, outcome_var, sc):\n",
    "    \n",
    "    sns.set_style('white')\n",
    "    fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(3, 6)) \n",
    "    ind = inds[outcome_var].iloc[:,0]\n",
    "    err = errs[outcome_var].iloc[:,0]\n",
    "    ind.plot.barh(xerr=err.values.T,ax=ax, color = ['#8980D4'], width=.9)\n",
    "    ax.set_ylabel('')\n",
    "    ax.legend().set_visible(False)\n",
    "    ax.set_xlabel('mu_star index', fontsize=14)\n",
    "\n",
    "    ylabels = ax.get_yticklabels()\n",
    "    ylabels = [item.get_text()[:-10] for item in ylabels]\n",
    "    ax.set_yticklabels(ylabels, fontsize=10)\n",
    "    #ax.set_title(\"2100\", fontsize=12)\n",
    "\n",
    "    plt.suptitle(\"{} in 2100\".format(outcome_var), y=0.94, fontsize=12)\n",
    "    plt.rcParams[\"figure.figsize\"] = [7.08,7.3]\n",
    "    plt.savefig('{}/Morris_{}_sc{}.png'.format(r'C:/Users/moallemie/EM_analysis/Fig/sa_ranking', outcome_var, sc), dpi=600,  bbox_inches='tight')\n",
    "    return fig\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = 3000\n",
    "for out, outcome_var in enumerate(outcome_vars):\n",
    "    plot_scores(inds, errs, outcome_var, sc)\n",
    "    plt.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
