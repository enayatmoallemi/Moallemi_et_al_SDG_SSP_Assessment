{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(r'C:\\Users\\moallemie\\EMAworkbench-master')\n",
    "sys.path.append(r'C:\\Users\\moallemie\\EM_analysis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from ema_workbench import load_results, ema_logging\n",
    "from ema_workbench.em_framework.salib_samplers import get_SALib_problem\n",
    "from SALib.analyze import morris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up number of scenarios, outcome of interest.\n",
    "sc = 500    # Specify the number of scenarios where the convergence in the SA indices occures\n",
    "t = 2100\n",
    "top_factor = 5\n",
    "outcome_var = 'Biomass Energy Production Indicator'  # Specify the outcome of interest for SA ranking verification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[MainProcess/INFO] results loaded succesfully from D:\\moallemie\\EM_analysis\\Data\\SDG_experiments_ranking_verification_Biomass Energy Production Indicator_sc500.tar.gz\n"
     ]
    }
   ],
   "source": [
    "ema_logging.log_to_stderr(ema_logging.INFO)\n",
    "    \n",
    "from Model_init import vensimModel\n",
    "    \n",
    "from ema_workbench import (TimeSeriesOutcome, \n",
    "                                   perform_experiments,\n",
    "                                   RealParameter, \n",
    "                                   CategoricalParameter,\n",
    "                                   ema_logging, \n",
    "                                   save_results,\n",
    "                                  load_results)\n",
    "\n",
    "directory = 'C:/Users/moallemie/EM_analysis/Model/'\n",
    "\n",
    "df_unc = pd.read_excel(directory+'ScenarioFramework.xlsx', sheet_name='Uncertainties')\n",
    "    \n",
    "\n",
    "df_unc['Min'] = df_unc['Min'] + df_unc['Reference'] * 0.75\n",
    "df_unc['Max'] = df_unc['Max'] + df_unc['Reference'] * 1.25\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "# From the Scenario Framework (all uncertainties), filter only those top 20 sensitive uncertainties under each outcome \n",
    "sa_dir='C:/Users/moallemie/EM_analysis/Data/'\n",
    "     \n",
    "    \n",
    "mu_df = pd.read_csv(sa_dir+\"MorrisIndices_{}_sc5000_t{}.csv\".format(outcome_var, t))\n",
    "mu_df.rename(columns={'Unnamed: 0': 'Uncertainty'}, inplace=True)\n",
    "mu_df.sort_values(by=['mu_star'], ascending=False, inplace=True)\n",
    "mu_df = mu_df.head(20)\n",
    "mu_unc = mu_df['Uncertainty']\n",
    "mu_unc_df = mu_unc.to_frame()\n",
    "    \n",
    "    \n",
    "# Remove the rest of insensitive uncertainties from the Scenario Framework and update df_unc\n",
    "keys = list(mu_unc_df.columns.values)\n",
    "i1 = df_unc.set_index(keys).index\n",
    "i2 = mu_unc_df.set_index(keys).index\n",
    "df_unc2 = df_unc[i1.isin(i2)]\n",
    "       \n",
    "    \n",
    "vensimModel.uncertainties = [RealParameter(row['Uncertainty'], row['Min'], row['Max']) for index, row in df_unc2.iterrows()]\n",
    "\n",
    "df_out = pd.read_excel(directory+'ScenarioFramework.xlsx', sheet_name='Outcomes')\n",
    "vensimModel.outcomes = [TimeSeriesOutcome(out) for out in df_out['Outcome']]\n",
    "\n",
    "\n",
    "r_dir = 'D:/moallemie/EM_analysis/Data/'\n",
    "results = load_results(r_dir+'SDG_experiments_ranking_verification_{}_sc{}.tar.gz'.format(outcome_var, sc))\n",
    "experiments, outcomes = results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating SA (Morris) metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sobol indice calculation as a function of number of scenarios and time\n",
    "\n",
    "def make_morris_df(scores, problem, outcome_var, sc, t):\n",
    "    scores_filtered = {k:scores[k] for k in ['mu_star','mu_star_conf','mu','sigma']}\n",
    "    Si_df = pd.DataFrame(scores_filtered, index=problem['names'])\n",
    "    sa_dir='C:/Users/moallemie/EM_analysis/Data/'\n",
    "    Si_df.to_csv(sa_dir+\"MorrisIndices_verification_{}_sc{}_t{}.csv\".format(outcome_var, sc, t))\n",
    "        \n",
    "    Si_df.sort_values(by=['mu_star'], ascending=False, inplace=True)\n",
    "    Si_df = Si_df.head(20)\n",
    "    \n",
    "    Si_df = Si_df.iloc[::-1]\n",
    "\n",
    "    indices = Si_df[['mu_star','mu']]\n",
    "    errors = Si_df[['mu_star_conf','sigma']]\n",
    "    return indices, errors\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the outcome variable, number of scenarios generated, and the timeslice you're interested in for SA\n",
    "problem = get_SALib_problem(vensimModel.uncertainties)\n",
    "X = experiments.iloc[:, :-3].values\n",
    "Y = outcomes[outcome_var][:,-1]\n",
    "scores = morris.analyze(problem, X, Y, print_to_console=False)\n",
    "inds, errs = make_morris_df(scores, problem, outcome_var, sc, t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting SA results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the ploting function\n",
    "def plot_scores(inds, errs, outcome_var, sc):\n",
    "    \n",
    "    sns.set_style('white')\n",
    "    fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(3, 6)) \n",
    "    ind = inds.iloc[:,0]\n",
    "    err = errs.iloc[:,0]\n",
    "    ind.plot.barh(xerr=err.values.T,ax=ax, color = ['#FCF6F5']*(20-top_factor)+['#C6B5ED']*top_factor, \n",
    "                  ecolor='dimgray', capsize=2,  width=.9)\n",
    "   \n",
    "    ax.set_ylabel('')\n",
    "    ax.legend().set_visible(False)\n",
    "    ax.set_xlabel('mu_star index', fontsize=12)\n",
    "\n",
    "    ylabels = ax.get_yticklabels()\n",
    "    ylabels = [item.get_text()[:-10] for item in ylabels]\n",
    "    ax.set_yticklabels(ylabels, fontsize=12)\n",
    "    ax.set_title(\"Number of experiments (N): \"+str(sc*21), fontsize=12)\n",
    "\n",
    "    plt.suptitle(\"{} in 2100\".format(outcome_var), y=0.94, fontsize=12)\n",
    "    plt.rcParams[\"figure.figsize\"] = [7.08,7.3]\n",
    "    plt.savefig('{}/Morris_verification_set_{}_sc{}.png'.format(r'C:/Users/moallemie/EM_analysis/Fig/sa_ranking', outcome_var, sc), dpi=600,  bbox_inches='tight')\n",
    "    return fig\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_scores(inds, errs, outcome_var, sc)\n",
    "plt.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
