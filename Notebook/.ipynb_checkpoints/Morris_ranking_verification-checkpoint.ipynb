{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(r'C:\\Users\\moallemie\\EMAworkbench-master')\n",
    "sys.path.append(r'C:\\Users\\moallemie\\EM_analysis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from ema_workbench import load_results, ema_logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up number of scenarios, outcome of interest, and number of parallel processors\n",
    "\n",
    "sc = 5000    # Specify the number of scenarios where the convergence in the SA indices occured\n",
    "t = 2100\n",
    "outcome_var = 'Gas Production Indicator'  # Specify the outcome of interest for SA ranking verification\n",
    "nprocess = 150"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the model, uncertainities, and SA results and generate initial experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[MainProcess/INFO] using 64 bit vensim\n",
      "[MainProcess/INFO] pool started\n",
      "[MainProcess/INFO] performing 2000 scenarios * 1 policies * 1 model(s) = 2000 experiments\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] 1200 cases completed\n",
      "[MainProcess/INFO] 1400 cases completed\n",
      "[MainProcess/INFO] 1600 cases completed\n",
      "[MainProcess/INFO] 1800 cases completed\n",
      "[MainProcess/INFO] 2000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] terminating pool\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "took 79.53942322731018 seconds\n"
     ]
    }
   ],
   "source": [
    "# Here we only generate experiments for loading the necessary components. \n",
    "#The actual results will be loaded in the next cell.\n",
    "\n",
    "# Open Excel input data from the notebook directory before runnign the code in multi-processing.\n",
    "# Close the folder where the results will be saved in multi-processing.\n",
    "# This line must be at the beginning for multi processing. \n",
    "if __name__ == '__main__':\n",
    "    \n",
    "   \n",
    "    ema_logging.log_to_stderr(ema_logging.INFO)\n",
    "    \n",
    "    #The model must be imoorted as .py file in parallel processing.\n",
    "    from Model_init import vensimModel\n",
    "    \n",
    "    from ema_workbench import (TimeSeriesOutcome, \n",
    "                                   perform_experiments,\n",
    "                                   RealParameter, \n",
    "                                   CategoricalParameter,\n",
    "                                   ema_logging, \n",
    "                                   save_results,\n",
    "                                  load_results)\n",
    "\n",
    "    directory = 'C:/Users/moallemie/EM_analysis/Model/'\n",
    "\n",
    "    df_unc = pd.read_excel(directory+'ScenarioFramework.xlsx', sheet_name='Uncertainties')\n",
    "    \n",
    "    # 0.5/1.5 multiplication is added to previous Min/Max cells for parameters with Reference values 0 \n",
    "    #or min/max manually set in the spreadsheet   \n",
    "    df_unc['Min'] = df_unc['Min'] + df_unc['Reference'] * 0.75\n",
    "    df_unc['Max'] = df_unc['Max'] + df_unc['Reference'] * 1.25\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    # From the Scenario Framework (all uncertainties), filter only those top 20 sensitive uncertainties under each outcome\n",
    "    \n",
    "    sa_dir='C:/Users/moallemie/EM_analysis/Data/'\n",
    "     \n",
    "    \n",
    "    mu_df = pd.read_csv(sa_dir+\"MorrisIndices_{}_sc{}_t{}.csv\".format(outcome_var, sc, t))\n",
    "    mu_df.rename(columns={'Unnamed: 0': 'Uncertainty'}, inplace=True)\n",
    "    mu_df.sort_values(by=['mu_star'], ascending=False, inplace=True)\n",
    "    mu_df = mu_df.head(20)\n",
    "    mu_unc = mu_df['Uncertainty']\n",
    "    mu_unc_df = mu_unc.to_frame()\n",
    "    \n",
    "    # Remove the rest of insensitive uncertainties from the Scenario Framework and update df_unc\n",
    "    keys = list(mu_unc_df.columns.values)\n",
    "    i1 = df_unc.set_index(keys).index\n",
    "    i2 = mu_unc_df.set_index(keys).index\n",
    "    df_unc2 = df_unc[i1.isin(i2)]\n",
    "    \n",
    "    \n",
    "    # Reorder the dataframe of mu index according to the model uncertainty. It will be used when we generate Sets 1 & 2 \n",
    "    mu_df1 = mu_df[['Uncertainty', 'mu_star']]\n",
    "    mu_df1 = mu_df1.set_index('Uncertainty')\n",
    "    mu_df1 = mu_df1.reindex(index=df_unc2['Uncertainty'])\n",
    "    mu_df1 = mu_df1.reset_index()\n",
    "       \n",
    "    \n",
    "    vensimModel.uncertainties = [RealParameter(row['Uncertainty'], row['Min'], row['Max']) for index, row in df_unc2.iterrows()]\n",
    "\n",
    "    df_out = pd.read_excel(directory+'ScenarioFramework.xlsx', sheet_name='Outcomes')\n",
    "    vensimModel.outcomes = [TimeSeriesOutcome(out) for out in df_out['Outcome']]\n",
    "\n",
    "\n",
    "  \n",
    "    from ema_workbench import MultiprocessingEvaluator\n",
    "    from ema_workbench.em_framework.evaluators import (MC, LHS, FAST, FF, PFF, SOBOL, MORRIS)\n",
    "\n",
    "    import  time\n",
    "    start = time.time()\n",
    "\n",
    "    with MultiprocessingEvaluator(vensimModel, n_processes=nprocess) as evaluator:\n",
    "        results = evaluator.perform_experiments(scenarios=2000, uncertainty_sampling=LHS) # The number of scenarios here is only for identifying the number of important parameters in SA results.\n",
    "\n",
    "    \n",
    "    \n",
    "    end = time.time()\n",
    "    print(\"took {} seconds\".format(end-start))\n",
    "    \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiments, outcomes = results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Where to draw the line between important and not important?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nModifed from Waterprogramming blog by Antonia Hadgimichael: https://github.com/antonia-had/SA_verification\\n\\nThe idea is that we create 2 additiopnal Sets (current SA samples are Set 1).\\n\\nWe can create a Set 2, using only the T most important factors from our Set 1 sample, \\nand fixing all other factors to their default values.\\n\\nWe can also create a Set 3, now fixing the T most important factors to defaults \\nand using the sampled values of all other factors from Set 1.\\n\\nIf we classified our important and unimportant factors correctly, \\nthen the correlation coefficient between the model outputs of Set 2 and Set 1 should approximate 1 \\n(since we’re fixing all factors that don’t matter), \\nand the correlation coefficient between outputs from Set 3 and Set 1 should approximate 0 \\n(since the factors we sampled are inconsequential to the output).\\n\\n'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Modifed from Waterprogramming blog by Antonia Hadgimichael: https://github.com/antonia-had/SA_verification\n",
    "\n",
    "The idea is that we create 2 additiopnal Sets (current SA samples are Set 1).\n",
    "\n",
    "We can create a Set 2, using only the T most important factors from our Set 1 sample, \n",
    "and fixing all other factors to their default values.\n",
    "\n",
    "We can also create a Set 3, now fixing the T most important factors to defaults \n",
    "and using the sampled values of all other factors from Set 1.\n",
    "\n",
    "If we classified our important and unimportant factors correctly, \n",
    "then the correlation coefficient between the model outputs of Set 2 and Set 1 should approximate 1 \n",
    "(since we’re fixing all factors that don’t matter), \n",
    "and the correlation coefficient between outputs from Set 3 and Set 1 should approximate 0 \n",
    "(since the factors we sampled are inconsequential to the output).\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort factors by importance\n",
    "inds_mu = mu_df1['mu_star'].values\n",
    "factors_sorted = np.argsort(inds_mu)[::-1]\n",
    "\n",
    "# Set up DataFrame of default values to use for experiment\n",
    "nsamples = len(experiments.index)\n",
    "\n",
    "defaultvalues = df_unc2['Reference'].values\n",
    "X_defaults = np.tile(defaultvalues,(nsamples, 1))\n",
    "\n",
    "\n",
    "# Create Set 1 from experiments\n",
    "exp_T = experiments.drop(['scenario', 'policy', 'model'], axis=1).T.reindex(df_unc2['Uncertainty'])\n",
    "exp_ordered = exp_T.T\n",
    "X_Set1 = exp_ordered.values\n",
    "\n",
    "# Create initial Sets 2 and 3\n",
    "X_Set2 = np.copy(X_defaults)\n",
    "X_Set3 = np.copy(X_Set1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to convert your Set 2 and Set 3 into experiments structure in the EMA Workbench\n",
    "\n",
    "def SA_experiments_to_scenarios(experiments, model=None):\n",
    "    '''\n",
    "\n",
    "    \"Slighlty modifed from the EMA Workbench\"\n",
    "    \n",
    "    This function transform a structured experiments array into a list\n",
    "    of Scenarios.\n",
    "\n",
    "    If model is provided, the uncertainties of the model are used.\n",
    "    Otherwise, it is assumed that all non-default columns are\n",
    "    uncertainties.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    experiments : numpy structured array\n",
    "                  a structured array containing experiments\n",
    "    model : ModelInstance, optional\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    a list of Scenarios\n",
    "\n",
    "    '''\n",
    "    from ema_workbench import Scenario\n",
    "    \n",
    "    # get the names of the uncertainties\n",
    "    uncertainties = [u.name for u in model.uncertainties]\n",
    "\n",
    "    # make list of of tuples of tuples\n",
    "    cases = []\n",
    "    cache = set()\n",
    "    for i in range(experiments.shape[0]):\n",
    "        case = {}\n",
    "        case_tuple = []\n",
    "        for uncertainty in uncertainties:\n",
    "            entry = experiments[uncertainty][i]\n",
    "            case[uncertainty] = entry\n",
    "            case_tuple.append(entry)\n",
    "\n",
    "        case_tuple = tuple(case_tuple)\n",
    "        cases.append(case)\n",
    "        cache.add((case_tuple))\n",
    "\n",
    "    scenarios = [Scenario(**entry) for entry in cases]\n",
    "\n",
    "    return scenarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[MainProcess/INFO] pool started\n",
      "[MainProcess/INFO] performing 2000 scenarios * 1 policies * 1 model(s) = 2000 experiments\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] 1200 cases completed\n",
      "[MainProcess/INFO] 1400 cases completed\n",
      "[MainProcess/INFO] 1600 cases completed\n",
      "[MainProcess/INFO] 1800 cases completed\n",
      "[MainProcess/INFO] 2000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] performing 2000 scenarios * 1 policies * 1 model(s) = 2000 experiments\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] 1200 cases completed\n",
      "[MainProcess/INFO] 1400 cases completed\n",
      "[MainProcess/INFO] 1600 cases completed\n",
      "[MainProcess/INFO] 1800 cases completed\n",
      "[MainProcess/INFO] 2000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] terminating pool\n",
      "[MainProcess/INFO] pool started\n",
      "[MainProcess/INFO] performing 2000 scenarios * 1 policies * 1 model(s) = 2000 experiments\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] 1200 cases completed\n",
      "[MainProcess/INFO] 1400 cases completed\n",
      "[MainProcess/INFO] 1600 cases completed\n",
      "[MainProcess/INFO] 1800 cases completed\n",
      "[MainProcess/INFO] 2000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] performing 2000 scenarios * 1 policies * 1 model(s) = 2000 experiments\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] 1200 cases completed\n",
      "[MainProcess/INFO] 1400 cases completed\n",
      "[MainProcess/INFO] 1600 cases completed\n",
      "[MainProcess/INFO] 1800 cases completed\n",
      "[MainProcess/INFO] 2000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] terminating pool\n",
      "[MainProcess/INFO] pool started\n",
      "[MainProcess/INFO] performing 2000 scenarios * 1 policies * 1 model(s) = 2000 experiments\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] 1200 cases completed\n",
      "[MainProcess/INFO] 1400 cases completed\n",
      "[MainProcess/INFO] 1600 cases completed\n",
      "[MainProcess/INFO] 1800 cases completed\n",
      "[MainProcess/INFO] 2000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] performing 2000 scenarios * 1 policies * 1 model(s) = 2000 experiments\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] 1200 cases completed\n",
      "[MainProcess/INFO] 1400 cases completed\n",
      "[MainProcess/INFO] 1600 cases completed\n",
      "[MainProcess/INFO] 1800 cases completed\n",
      "[MainProcess/INFO] 2000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] terminating pool\n",
      "[MainProcess/INFO] pool started\n",
      "[MainProcess/INFO] performing 2000 scenarios * 1 policies * 1 model(s) = 2000 experiments\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] 1200 cases completed\n",
      "[MainProcess/INFO] 1400 cases completed\n",
      "[MainProcess/INFO] 1600 cases completed\n",
      "[MainProcess/INFO] 1800 cases completed\n",
      "[MainProcess/INFO] 2000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] performing 2000 scenarios * 1 policies * 1 model(s) = 2000 experiments\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] 1200 cases completed\n",
      "[MainProcess/INFO] 1400 cases completed\n",
      "[MainProcess/INFO] 1600 cases completed\n",
      "[MainProcess/INFO] 1800 cases completed\n",
      "[MainProcess/INFO] 2000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] terminating pool\n",
      "[MainProcess/INFO] pool started\n",
      "[MainProcess/INFO] performing 2000 scenarios * 1 policies * 1 model(s) = 2000 experiments\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] 1200 cases completed\n",
      "[MainProcess/INFO] 1400 cases completed\n",
      "[MainProcess/INFO] 1600 cases completed\n",
      "[MainProcess/INFO] 1800 cases completed\n",
      "[MainProcess/INFO] 2000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] performing 2000 scenarios * 1 policies * 1 model(s) = 2000 experiments\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] 1200 cases completed\n",
      "[MainProcess/INFO] 1400 cases completed\n",
      "[MainProcess/INFO] 1600 cases completed\n",
      "[MainProcess/INFO] 1800 cases completed\n",
      "[MainProcess/INFO] 2000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] terminating pool\n",
      "[MainProcess/INFO] pool started\n",
      "[MainProcess/INFO] performing 2000 scenarios * 1 policies * 1 model(s) = 2000 experiments\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] 1200 cases completed\n",
      "[MainProcess/INFO] 1400 cases completed\n",
      "[MainProcess/INFO] 1600 cases completed\n",
      "[MainProcess/INFO] 1800 cases completed\n",
      "[MainProcess/INFO] 2000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] performing 2000 scenarios * 1 policies * 1 model(s) = 2000 experiments\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] 1200 cases completed\n",
      "[MainProcess/INFO] 1400 cases completed\n",
      "[MainProcess/INFO] 1600 cases completed\n",
      "[MainProcess/INFO] 1800 cases completed\n",
      "[MainProcess/INFO] 2000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] terminating pool\n",
      "[MainProcess/INFO] pool started\n",
      "[MainProcess/INFO] performing 2000 scenarios * 1 policies * 1 model(s) = 2000 experiments\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] 1200 cases completed\n",
      "[MainProcess/INFO] 1400 cases completed\n",
      "[MainProcess/INFO] 1600 cases completed\n",
      "[MainProcess/INFO] 1800 cases completed\n",
      "[MainProcess/INFO] 2000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] performing 2000 scenarios * 1 policies * 1 model(s) = 2000 experiments\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] 1200 cases completed\n",
      "[MainProcess/INFO] 1400 cases completed\n",
      "[MainProcess/INFO] 1600 cases completed\n",
      "[MainProcess/INFO] 1800 cases completed\n",
      "[MainProcess/INFO] 2000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] terminating pool\n",
      "[MainProcess/INFO] pool started\n",
      "[MainProcess/INFO] performing 2000 scenarios * 1 policies * 1 model(s) = 2000 experiments\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] 1200 cases completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[MainProcess/INFO] 1400 cases completed\n",
      "[MainProcess/INFO] 1600 cases completed\n",
      "[MainProcess/INFO] 1800 cases completed\n",
      "[MainProcess/INFO] 2000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] performing 2000 scenarios * 1 policies * 1 model(s) = 2000 experiments\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] 1200 cases completed\n",
      "[MainProcess/INFO] 1400 cases completed\n",
      "[MainProcess/INFO] 1600 cases completed\n",
      "[MainProcess/INFO] 1800 cases completed\n",
      "[MainProcess/INFO] 2000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] terminating pool\n",
      "[MainProcess/INFO] pool started\n",
      "[MainProcess/INFO] performing 2000 scenarios * 1 policies * 1 model(s) = 2000 experiments\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] 1200 cases completed\n",
      "[MainProcess/INFO] 1400 cases completed\n",
      "[MainProcess/INFO] 1600 cases completed\n",
      "[MainProcess/INFO] 1800 cases completed\n",
      "[MainProcess/INFO] 2000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] performing 2000 scenarios * 1 policies * 1 model(s) = 2000 experiments\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] 1200 cases completed\n",
      "[MainProcess/INFO] 1400 cases completed\n",
      "[MainProcess/INFO] 1600 cases completed\n",
      "[MainProcess/INFO] 1800 cases completed\n",
      "[MainProcess/INFO] 2000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] terminating pool\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "took 1191.3621530532837 seconds\n"
     ]
    }
   ],
   "source": [
    "# Run the models for the top n factors in Set 2 and Set 3 and generate correlation figures\n",
    "\n",
    "if __name__ == '__main__':\n",
    "     \n",
    "    ema_logging.log_to_stderr(ema_logging.INFO)\n",
    "    \n",
    "    #The model must be imoorted as .py file in parallel processing.\n",
    "    from Model_init import vensimModel\n",
    "    \n",
    "    from ema_workbench import (TimeSeriesOutcome, \n",
    "                                   perform_experiments,\n",
    "                                   RealParameter, \n",
    "                                   CategoricalParameter,\n",
    "                                   ema_logging, \n",
    "                                   save_results,\n",
    "                                  load_results)\n",
    "    \n",
    "    vensimModel.outcomes = [TimeSeriesOutcome(outcome_var)]\n",
    "\n",
    "    from ema_workbench import MultiprocessingEvaluator\n",
    "        \n",
    "    coefficient_S1_S2 = 0\n",
    "    coefficient_S1_S3 = 0.99\n",
    "    \n",
    "    import  time\n",
    "    start = time.time()\n",
    "        \n",
    "    n = 0    \n",
    "    for f in range(1, len(factors_sorted)+1):\n",
    "        ntopfactors = f\n",
    "        \n",
    "        if (coefficient_S1_S2 <=0.95 or coefficient_S1_S3 >= 0.1):\n",
    "\n",
    "            for i in range(ntopfactors): #Loop through all important factors\n",
    "                X_Set2[:,factors_sorted[i]] = X_Set1[:,factors_sorted[i]] #Fix use samples for important\n",
    "                X_Set3[:,factors_sorted[i]] = X_defaults[:,factors_sorted[i]] #Fix important to defaults\n",
    "\n",
    "            X_Set2_exp = pd.DataFrame(data=X_Set2, columns=df_unc2['Uncertainty'].tolist())\n",
    "            X_Set3_exp = pd.DataFrame(data=X_Set3, columns=df_unc2['Uncertainty'].tolist())\n",
    "\n",
    "            scenarios_Set2 = SA_experiments_to_scenarios(X_Set2_exp, model=vensimModel)\n",
    "            scenarios_Set3 = SA_experiments_to_scenarios(X_Set3_exp, model=vensimModel)\n",
    "\n",
    "            \n",
    "            with MultiprocessingEvaluator(vensimModel, n_processes=nprocess) as evaluator:\n",
    "                    experiments_Set2, outcomes_Set2 = evaluator.perform_experiments(scenarios=scenarios_Set2)\n",
    "                    experiments_Set3, outcomes_Set3 = evaluator.perform_experiments(scenarios=scenarios_Set3)\n",
    "\n",
    "\n",
    "            # Calculate coefficients of correlation\n",
    "            data_Set1 = outcomes[outcome_var][:,-1]\n",
    "            data_Set2 = outcomes_Set2[outcome_var][:,-1]\n",
    "            data_Set3 = outcomes_Set3[outcome_var][:,-1]\n",
    "\n",
    "            coefficient_S1_S2 = np.corrcoef(data_Set1,data_Set2)[0][1]\n",
    "            coefficient_S1_S3 = np.corrcoef(data_Set1,data_Set3)[0][1]\n",
    "\n",
    "            # Plot outputs and correlation\n",
    "            fig =  plt.figure(figsize=(14,7))\n",
    "            ax1 = fig.add_subplot(1,2,1)\n",
    "            ax1.plot(data_Set1,data_Set1, color='#39566E')\n",
    "            ax1.scatter(data_Set1,data_Set2, color='#8DCCFC')\n",
    "            ax1.set_xlabel(\"Set 1\",fontsize=14)\n",
    "            ax1.set_ylabel(\"Set 2\",fontsize=14)\n",
    "            ax1.tick_params(axis='both', which='major', labelsize=10)\n",
    "            ax1.set_title('Set 1 vs Set 2 - ' + str(f) + ' top factors',fontsize=15)\n",
    "            ax1.text(0.05,0.95,'R= '+\"{0:.3f}\".format(coefficient_S1_S2),transform = ax1.transAxes,fontsize=16)\n",
    "            ax2 = fig.add_subplot(1,2,2)\n",
    "            ax2.plot(data_Set1,data_Set1, color='#39566E')\n",
    "            ax2.scatter(data_Set1,data_Set3, color='#FFE0D5')\n",
    "            ax2.set_xlabel(\"Set 1\",fontsize=14)\n",
    "            ax2.set_ylabel(\"Set 3\",fontsize=14)\n",
    "            ax2.tick_params(axis='both', which='major', labelsize=10)\n",
    "            ax2.set_title('Set 1 vs Set 3 - ' + str(f) + ' top factors',fontsize=15)\n",
    "            ax2.text(0.05,0.95,'R= '+\"{0:.3f}\".format(coefficient_S1_S3),transform = ax2.transAxes,fontsize=16)\n",
    "            plt.savefig('{}/{}_{}_topfactors.png'.format(r'C:/Users/moallemie/EM_analysis/Fig/sa_verification', outcome_var, str(f)))\n",
    "            plt.close()\n",
    "            \n",
    "            n = n+1\n",
    "            \n",
    "\n",
    "    \n",
    "    end = time.time()\n",
    "    print(\"took {} seconds\".format(end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the ploting function\n",
    "def plot_scores(outcome_var, n, sc):\n",
    "    \n",
    "    mu_df2 = mu_df.set_index('Uncertainty')\n",
    "    mu_df2.sort_values(by=['mu_star'], ascending=True, inplace=True)\n",
    "\n",
    "    sns.set_style('white')\n",
    "    fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(3, 6)) \n",
    "    ind = mu_df2.iloc[:,0]\n",
    "    err = mu_df2.iloc[:,1]\n",
    "    ind.plot.barh(xerr=err.values.T,ax=ax, color = ['#D7F0BC']*(20-n)+['#62C890']*n, \n",
    "                  ecolor='dimgray', capsize=2,  width=.9)\n",
    "   \n",
    "    ax.set_ylabel('')\n",
    "    ax.legend().set_visible(False)\n",
    "    ax.set_xlabel('mu_star index', fontsize=12)\n",
    "\n",
    "    ylabels = ax.get_yticklabels()\n",
    "    ylabels = [item.get_text()[:-10] for item in ylabels]\n",
    "    ax.set_yticklabels(ylabels, fontsize=12)\n",
    "    ax.set_title(\"Number of experiments (N): \"+str(sc*21), fontsize=12)\n",
    "\n",
    "    plt.suptitle(\"{} in 2100\".format(outcome_var), y=0.94, fontsize=12)\n",
    "    plt.rcParams[\"figure.figsize\"] = [7.08,7.3]\n",
    "    plt.savefig('{}/Morris_ranking_{}_sc{}.png'.format(r'C:/Users/moallemie/EM_analysis/Fig/sa_ranking', outcome_var, sc), dpi=600,  bbox_inches='tight')\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_scores(outcome_var, n, sc)\n",
    "plt.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
