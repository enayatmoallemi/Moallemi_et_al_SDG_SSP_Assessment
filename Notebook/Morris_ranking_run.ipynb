{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(r'C:\\Users\\moallemie\\EMAworkbench-master')\n",
    "sys.path.append(r'C:\\Users\\moallemie\\GitHub\\SSPs_SDGs_Assessment')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from ema_workbench import load_results, ema_logging\n",
    "from ema_workbench.em_framework.salib_samplers import get_SALib_problem\n",
    "from SALib.analyze import morris"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load model, uncertainities, outcomes; Run experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def generate_experiments(n_scenarios):\n",
    "    \n",
    "    #The model must be imoorted as .py file in parallel processing.\n",
    "    from Model_init import vensimModel\n",
    "    \n",
    "    from ema_workbench import (TimeSeriesOutcome, \n",
    "                                   perform_experiments,\n",
    "                                   RealParameter, \n",
    "                                   CategoricalParameter,\n",
    "                                   ema_logging, \n",
    "                                   save_results,\n",
    "                                  load_results)\n",
    "\n",
    "    directory = 'C:/Users/moallemie/GitHub/SSPs_SDGs_Assessment/Model/'\n",
    "\n",
    "    df_unc = pd.read_excel(directory+'ScenarioFramework.xlsx', sheet_name='Uncertainties')\n",
    "    \n",
    "    # 0.5/1.5 multiplication is added to previous Min/Max cells for parameters with Reference values 0 \n",
    "    #or min/max manually set in the spreadsheet   \n",
    "    #df_unc['Min'] = df_unc['Min'] + df_unc['Reference'] * 0.75\n",
    "    #df_unc['Max'] = df_unc['Max'] + df_unc['Reference'] * 1.25\n",
    "\n",
    "    vensimModel.uncertainties = [RealParameter(row['Uncertainty'], row['Min'], row['Max']) for index, row in df_unc.iterrows()]\n",
    "\n",
    "    df_out = pd.read_excel(directory+'ScenarioFramework.xlsx', sheet_name='Outcomes')\n",
    "    vensimModel.outcomes = [TimeSeriesOutcome(out) for out in df_out['Outcome']]\n",
    "\n",
    "    from ema_workbench import MultiprocessingEvaluator\n",
    "    from ema_workbench.em_framework.evaluators import (MC, LHS, FAST, FF, PFF, SOBOL, MORRIS)\n",
    "\n",
    "\n",
    "    try: \n",
    "        with MultiprocessingEvaluator(vensimModel, n_processes=230) as evaluator:\n",
    "            results = evaluator.perform_experiments(scenarios=n_scenarios, uncertainty_sampling=MORRIS)\n",
    "    except (BrokenPipeError, IOError):\n",
    "        pass\n",
    "        \n",
    "    fn = 'C:/Users/moallemie/GitHub/SSPs_SDGs_Assessment/Data/Morris_results/SDG_experiments_sc{}.tar.gz'.format(n_scenarios)\n",
    "\n",
    "    save_results(results, fn)\n",
    "    \n",
    "    experiments, outcomes = results\n",
    "    \n",
    "    return vensimModel.uncertainties, experiments, outcomes, results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating SA (Morris) metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_morris_df(scores, problem, outcome_var, sc, t):\n",
    "    scores_filtered = {k:scores[k] for k in ['mu_star','mu_star_conf','mu','sigma']}\n",
    "    Si_df = pd.DataFrame(scores_filtered, index=problem['names'])\n",
    "    sa_dir = 'C:/Users/moallemie/GitHub/SSPs_SDGs_Assessment/Data/Morris_results/'\n",
    "    Si_df.to_csv(sa_dir+\"MorrisIndices_{}_sc{}_t{}_test.csv\".format(outcome_var, sc, t))\n",
    "    \n",
    "    Si_df.sort_values(by=['mu_star'], ascending=False, inplace=True)\n",
    "    Si_df = Si_df.head(20)\n",
    "    \n",
    "    Si_df = Si_df.iloc[::-1]\n",
    "\n",
    "    indices = Si_df[['mu_star','mu']]\n",
    "    errors = Si_df[['mu_star_conf','sigma']]\n",
    "    return indices, errors\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_scores(inds, errs, outcome_var, sc, t):\n",
    "    sns.set_style('white')\n",
    "    fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(3, 6)) \n",
    "    ind = inds[outcome_var].iloc[:,0]\n",
    "    err = errs[outcome_var].iloc[:,0]\n",
    "    ind.plot.barh(xerr=err.values.T,ax=ax, color = ['#62C890'], width=.9)\n",
    "    ax.set_ylabel('')\n",
    "    ax.legend().set_visible(False)\n",
    "    ax.set_xlabel('mu_star index', fontsize=14)\n",
    "\n",
    "    ylabels = ax.get_yticklabels()\n",
    "    ylabels = [item.get_text()[:-10] for item in ylabels]\n",
    "    ax.set_yticklabels(ylabels, fontsize=10)\n",
    "    #ax.set_title(\"2100\", fontsize=12)\n",
    "\n",
    "    plt.suptitle('{} in {}'.format(outcome_var, t), y=0.94, fontsize=12)\n",
    "    plt.rcParams[\"figure.figsize\"] = [7.08,7.3]\n",
    "    plt.savefig('{}/Morris_ranking_{}_sc{}_{}.png'.format(r'C:/Users/moallemie/GitHub/SSPs_SDGs_Assessment/Fig/sa_ranking', outcome_var, sc, t), \n",
    "                dpi=600,  bbox_inches='tight')\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[MainProcess/INFO] using 64 bit vensim\n",
      "[MainProcess/INFO] pool started\n",
      "[MainProcess/INFO] performing 575000 scenarios * 1 policies * 1 model(s) = 575000 experiments\n",
      "[MainProcess/INFO] 57500 cases completed\n",
      "[MainProcess/INFO] 115000 cases completed\n",
      "[MainProcess/INFO] 172500 cases completed\n",
      "[MainProcess/INFO] 230000 cases completed\n",
      "[MainProcess/INFO] 287500 cases completed\n",
      "[MainProcess/INFO] 345000 cases completed\n",
      "[MainProcess/INFO] 402500 cases completed\n",
      "[MainProcess/INFO] 460000 cases completed\n",
      "[MainProcess/INFO] 517500 cases completed\n",
      "[MainProcess/INFO] 575000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] terminating pool\n",
      "[MainProcess/INFO] results saved successfully to C:\\Users\\moallemie\\GitHub\\SSPs_SDGs_Assessment\\Data\\Morris_results\\SDG_experiments_sc5000.tar.gz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "took 13099.86015033722 seconds\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    \n",
    "    ema_logging.log_to_stderr(ema_logging.INFO)\n",
    "\n",
    "    targetyear_ind = {2030: 130, 2050:150, 2100:200}\n",
    "    import  time\n",
    "    start = time.time()\n",
    "    for n_scenarios in [250, 500, 750, 1000, 1500, 2000, 3000, 5000]:\n",
    "        uncertainties, experiments, outcomes, results = generate_experiments(n_scenarios)\n",
    "        sc = n_scenarios\n",
    "        outcome_vars = list(outcomes.keys())[1:]\n",
    "        problem = get_SALib_problem(uncertainties)\n",
    "        for t in list(targetyear_ind.keys()):\n",
    "            inds ={}\n",
    "            errs = {}\n",
    "            for i, outcome_var in enumerate(outcome_vars):\n",
    "                X = experiments.iloc[:, :-3].values\n",
    "                Y = outcomes[outcome_var][:,targetyear_ind[t]]\n",
    "                scores = morris.analyze(problem, X, Y, print_to_console=False)\n",
    "                inds[outcome_var], errs[outcome_var] = make_morris_df(scores, problem, outcome_var, sc, t)\n",
    "            for out, outcome_var in enumerate(outcome_vars):\n",
    "                plot_scores(inds, errs, outcome_var, sc, t)\n",
    "                plt.close()\n",
    "    end = time.time()\n",
    "    print(\"took {} seconds\".format(end-start))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
